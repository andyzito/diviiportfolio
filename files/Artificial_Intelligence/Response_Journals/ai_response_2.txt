Hierarchical control structures are good for many things. For example, when building an AI, it is easier to create  a working agent than if you try to design an entire internal world model, reasoning system, etc. from the ground up. That is, you COULD try to build an AI the same way you would build a house. You know that a house needs a roof, and walls, and a floor, and rooms, and etc. You could create these pieces and put them together and voila! you have a house. Of course, this works because we know already know how to build houses. We know all the pieces and how they need to fit together. Unfortunately, we DON'T know that about intelligence. We know what intelligence looks like in general -- it looks like us -- but we don't have any idea about how it is put together.

So trying to build a human-level AI by making a virtual human is a pretty daunting task. You would have to have a memory system, and a reasoning/logic system, and a virtual representation of sense data, and some way to include emotions perhaps, and goodness knows what else. Hierarchical control structures offer an alternative. Build something that works FIRST. Even if it is the equivalent of a cardboard box in our house metaphor, at least it will keep the rain off. Even if all your AI can do is bounce off of walls. Because once it can bounce off of walls, maybe you can design it to not hit the walls in the first place. And then you can design it to go somewhere in particular while not bouncing off of walls. And on and on, incrementally increasing the complexity of the system, until eventually your cardboard box is a hut, and eventually a house.

The limitations to this approach are that it is unclear how we can move from this incremental, modular design to something that resembles integrated human-level intelligence. It is clear that hierarchical control structures can take us pretty far, but it is also clear that our brains at least APPEAR to function differently. We perceive a centralized internal world, with a single moderator connected to many different modules and receiving all of their data and sending out all the signals to make you eat cereal or watch Netflix or whatever. Neurologically speaking this is probably an illusion. But still, how does this illusion result from a bunch of little modules talking to one another with no plan or control center? A mystery indeed, and one that perhaps could be solved if we made a complicated enough hierarchical control structure AI!